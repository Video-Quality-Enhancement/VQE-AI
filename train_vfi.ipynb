{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4b4a40-6d6c-49f2-a141-861b54bb0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_ssim_changed as pytorch_ssim\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import perceptual_loss\n",
    "import cv2\n",
    "\n",
    "from vfi.vfi_new import VFIModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba42c2a2-1999-4d12-85db-ac45bacfa920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vimeo90kDataset(Dataset):\n",
    "    def __init__(self, root, mode='train'):\n",
    "        assert mode in ['train', 'test'], \"Invalid mode, it must be either 'train' or 'test'.\"\n",
    "        self.mode = mode\n",
    "        self.root = root\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        \n",
    "        # Load the list of sequences for the specified mode\n",
    "        if self.mode == 'train':\n",
    "            listfile = os.path.join(self.root, 'sep_trainlist.txt')\n",
    "        else:\n",
    "            listfile = os.path.join(self.root, 'sep_testlist.txt')\n",
    "        with open(listfile) as f:\n",
    "            self.sequences = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Load the seven frames of the sequence\n",
    "        seq_dir = os.path.join(self.root, 'sequence', self.sequences[index])\n",
    "        frames = [cv2.imread(os.path.join(seq_dir, f'im{i}.png')) for i in range(1, 8)]\n",
    "\n",
    "        # Apply transforms to each frame\n",
    "        frames = [self.transforms(frame) for frame in frames]\n",
    "        \n",
    "        # Create input and target pairs\n",
    "        inputs, targets = [], []\n",
    "        for i in range(0, 5):\n",
    "            inputs.append(torch.cat([frames[i], frames[i+2]], dim=0))\n",
    "            targets.append(frames[i+1])\n",
    "        \n",
    "        # # Apply transforms\n",
    "        # inputs = [self.transforms(input) for input in inputs]\n",
    "        # targets = [self.transforms(target) for target in targets]\n",
    "        \n",
    "        # Return input and target pairs as a dictionary\n",
    "        return {'inputs': inputs, 'targets': targets}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58546cef-b028-447d-b734-15a4fc80cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"E:/Engineering/Capstone-Project/Datasets/vimeo_90k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24eeaad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "trainset = Vimeo90kDataset(root_dir, mode='train')\n",
    "testset = Vimeo90kDataset(root_dir, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d505861-4e37-4386-b0fd-3cd06e4c8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders \n",
    "train_dataloader = DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f87d4e-2fe9-4344-baec-64508e282525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "batch_size = 16\n",
    "num_epochs = 500\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b886f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VFIModel().to(device)\n",
    "# criterion = pytorch_ssim.SSIM(window_size=11)\n",
    "criterion = SSIM(win_size=11, win_sigma=1.5, data_range=1, size_average=True, channel=1)\n",
    "# criterion = perceptual_loss.PerceptualLoss(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d3c015-e069-4e11-9fff-93d244301136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7262d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 10778644\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "num_params = sum(p.numel() for p in params)\n",
    "print(f\"Number of parameters in the model: {num_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dabb0158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VFIModel(\n",
       "  (optical_flow): FlowNet(\n",
       "    (netFeatures): Features(\n",
       "      (netOne): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (netTwo): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (netThr): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (netFou): Sequential(\n",
       "        (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (netFiv): Sequential(\n",
       "        (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "      (netSix): Sequential(\n",
       "        (0): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "      )\n",
       "    )\n",
       "    (netMatching): ModuleList(\n",
       "      (0): Matching(\n",
       "        (netFeat): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netUpflow): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
       "        (netUpcorr): ConvTranspose2d(49, 49, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=49, bias=False)\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        )\n",
       "      )\n",
       "      (1): Matching(\n",
       "        (netFeat): Sequential()\n",
       "        (netUpflow): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
       "        (netUpcorr): ConvTranspose2d(49, 49, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=49, bias=False)\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (2): Matching(\n",
       "        (netFeat): Sequential()\n",
       "        (netUpflow): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (3): Matching(\n",
       "        (netFeat): Sequential()\n",
       "        (netUpflow): ConvTranspose2d(2, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): Matching(\n",
       "        (netFeat): Sequential()\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (netSubpixel): ModuleList(\n",
       "      (0): Subpixel(\n",
       "        (netFeat): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(130, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        )\n",
       "      )\n",
       "      (1): Subpixel(\n",
       "        (netFeat): Sequential()\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(130, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (2): Subpixel(\n",
       "        (netFeat): Sequential()\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(194, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (3): Subpixel(\n",
       "        (netFeat): Sequential()\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): Subpixel(\n",
       "        (netFeat): Sequential()\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(386, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (netRegularization): ModuleList(\n",
       "      (0): Regularization(\n",
       "        (netFeat): Sequential(\n",
       "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(131, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): LeakyReLU(negative_slope=0.1)\n",
       "          (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (9): LeakyReLU(negative_slope=0.1)\n",
       "          (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (11): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netDist): Sequential(\n",
       "          (0): Conv2d(32, 49, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n",
       "          (1): Conv2d(49, 49, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "        )\n",
       "        (netScaleX): Conv2d(49, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (netScaleY): Conv2d(49, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Regularization(\n",
       "        (netFeat): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(131, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): LeakyReLU(negative_slope=0.1)\n",
       "          (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (9): LeakyReLU(negative_slope=0.1)\n",
       "          (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (11): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netDist): Sequential(\n",
       "          (0): Conv2d(32, 25, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "          (1): Conv2d(25, 25, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "        )\n",
       "        (netScaleX): Conv2d(25, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (netScaleY): Conv2d(25, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Regularization(\n",
       "        (netFeat): Sequential(\n",
       "          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(131, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): LeakyReLU(negative_slope=0.1)\n",
       "          (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (9): LeakyReLU(negative_slope=0.1)\n",
       "          (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (11): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netDist): Sequential(\n",
       "          (0): Conv2d(32, 25, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "          (1): Conv2d(25, 25, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "        )\n",
       "        (netScaleX): Conv2d(25, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (netScaleY): Conv2d(25, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): Regularization(\n",
       "        (netFeat): Sequential()\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(131, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): LeakyReLU(negative_slope=0.1)\n",
       "          (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (9): LeakyReLU(negative_slope=0.1)\n",
       "          (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (11): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netDist): Sequential(\n",
       "          (0): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (netScaleX): Conv2d(9, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (netScaleY): Conv2d(9, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (4): Regularization(\n",
       "        (netFeat): Sequential()\n",
       "        (netMain): Sequential(\n",
       "          (0): Conv2d(195, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): LeakyReLU(negative_slope=0.1)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (3): LeakyReLU(negative_slope=0.1)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (5): LeakyReLU(negative_slope=0.1)\n",
       "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): LeakyReLU(negative_slope=0.1)\n",
       "          (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (9): LeakyReLU(negative_slope=0.1)\n",
       "          (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (11): LeakyReLU(negative_slope=0.1)\n",
       "        )\n",
       "        (netDist): Sequential(\n",
       "          (0): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (netScaleX): Conv2d(9, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (netScaleY): Conv2d(9, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fusion1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fusion2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fusion3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fusion4): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d75321",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('model_weights/vfi/vfi-last_epoch_weights.pt'):\n",
    "    model.load_state_dict(torch.load('vfi-last_epoch_weights.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276240f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_epoch_step_no(epoch: int, step: int):\n",
    "    path = \"model_weights/vfi/vfi_epoch_step.bin\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(f\"Epoch: {epoch}, Step: {step}\")\n",
    "\n",
    "def read_epoch_step_no():\n",
    "    path = \"model_weights/vfi/vfi_epoch_step.bin\"\n",
    "    with open(path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    epoch, step = map(int, [x.split(': ')[1] for x in content.split(',')])\n",
    "    return epoch, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85538db-98c9-4193-b049-68f7903ecbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training... epoch: 0\n",
      "frame1.size(): torch.Size([1, 3, 256, 448]), frame2.size(): torch.Size([1, 3, 256, 448])\n",
      "intWidth: 448, intHeight: 256\n",
      "frame1.size(): torch.Size([1, 3, 256, 448]), frame2.size(): torch.Size([1, 3, 256, 448])\n",
      "intWidth: 448, intHeight: 256\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 4.00 GiB total capacity; 3.32 GiB already allocated; 0 bytes free; 3.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[39m=\u001b[39m [model(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mto(device)) \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs]\n\u001b[0;32m     18\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([criterion(output, target) \u001b[39mfor\u001b[39;00m output, target \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(outputs, targets)])\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     20\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[39m=\u001b[39m [model(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mto(device)) \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs]\n\u001b[0;32m     18\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([criterion(output, target) \u001b[39mfor\u001b[39;00m output, target \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(outputs, targets)])\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     20\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32me:\\Engineering\\Capstone-Project\\PROJECT\\cp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Engineering\\Capstone-Project\\PROJECT\\vfi\\vfi_new.py:72\u001b[0m, in \u001b[0;36mVFIModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x))\n\u001b[0;32m     71\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[1;32m---> 72\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(x))\n\u001b[0;32m     73\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(x)\n\u001b[0;32m     75\u001b[0m \u001b[39m# Fuse feature maps\u001b[39;00m\n",
      "File \u001b[1;32me:\\Engineering\\Capstone-Project\\PROJECT\\cp\\lib\\site-packages\\torch\\nn\\functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[0;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 4.00 GiB total capacity; 3.32 GiB already allocated; 0 bytes free; 3.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if os.path.exists('model_weights/vfi/vfi-last_step_weights.pt'):\n",
    "    model.load_state_dict(torch.load('model_weights/vfi/vfi-last_step_weights.pt'))\n",
    "    print(\"Model loaded successfully..!!\")\n",
    "\n",
    "epoch_done, step_done = read_epoch_step_no()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'training... epoch: {epoch}')\n",
    "\n",
    "    if epoch < epoch_done:\n",
    "        continue\n",
    "    \n",
    "    model.train()\n",
    "    model.optical_flow.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # print(f'len(train_dataloader): {len(train_dataloader)}')\n",
    "    total_steps = len(train_dataloader)\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        if i < step_done:\n",
    "            continue\n",
    "        # print(data)\n",
    "        inputs, targets = data['inputs'], data['targets']\n",
    "        # inputs, targets = inputs, targets = [input.to(device) for input in inputs], [target.to(device) for target in targets]\n",
    "        targets = [Variable(target.to(device),  requires_grad=False) for target in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = [model(input.to(device)) for input in inputs]\n",
    "        loss = torch.mean(torch.stack([1-criterion(output, target) for output, target in zip(outputs, targets)]))\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ssim_value = torch.mean(torch.stack([ssim(output, target).item() for output, target in zip(outputs, targets)]))\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate the elapsed time and remaining time\n",
    "        elapsed_time = time.time() - start_time\n",
    "        remaining_time = (elapsed_time / (i+1)) * (total_steps - i - 1)\n",
    "\n",
    "        torch.save(model.state_dict(), f'model_weights/vfi/vfi-last_step_weights.pt')\n",
    "        write_epoch_step_no(epoch, i+1)\n",
    "        # Print the number of steps, elapsed time, and remaining time\n",
    "        print(f\"Step {i+1}/{total_steps}, Loss: {loss.item()}, ssim_value: {ssim_value.item()}, Elapsed time: {elapsed_time:.2f}s, Remaining time: {remaining_time:.2f}s\")\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_elapsed_time = epoch_end_time - epoch_start_time\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_dataloader)}, Elapsed time: {epoch_elapsed_time:.2f}s\")\n",
    "\n",
    "    torch.save(model.state_dict(), f'model_weights/vfi/vfi-last_epoch_weights.pt')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_dataloader):\n",
    "                inputs, targets = data['inputs'], data['targets']\n",
    "                inputs, targets = [input.to(device) for input in inputs], [target.to(device) for target in targets]\n",
    "                # inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = [model(input) for input in inputs]\n",
    "                # loss = sum([criterion(output, target) for output, target in zip(outputs, targets)]) / len(outputs)\n",
    "                loss = torch.mean(torch.stack([criterion(output, target.to(device)) for output, target in zip(outputs, targets)]))\n",
    "\n",
    "                ssim_value = torch.mean(torch.stack([ssim(output, target).item() for output, target in zip(outputs, targets)]))\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Print the number of steps\n",
    "                print(f\"Step {i+1}/{total_steps}, Loss: {loss.item()}, ssim_value: {ssim_value.item()}\")\n",
    "\n",
    "        print(f\"Test Loss: {test_loss / len(test_dataloader)}\")\n",
    "        torch.save(model.state_dict(), f'model_weights/vfi/vfi-epoch_{epoch + 1}_weights.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84525336-d9f3-4319-b3e3-35cc473b03e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
